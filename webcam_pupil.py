import cv2
import time
import os
import numpy as np
import torch
from ultralytics import YOLO

def run_pupil_tracking():
    # ================= ğŸ”§ é…ç½®åŒºåŸŸ =================
    # ä»»åŠ¡å (ä½¿ç”¨ä½ æ•ˆæœæœ€å¥½çš„æ¨¡å‹ï¼Œæ¯”å¦‚ v8n)
    task_name = 'v8_n_eye_mouth' # æˆ–è€…æ˜¯ 'yolov8n_eye'ï¼Œè¯·æ ¹æ®å®é™…æ–‡ä»¶å¤¹ä¿®æ”¹
    
    # æ¨¡å‹è·¯å¾„
    model_path = os.path.join('runs', 'detect', task_name, 'weights', 'best.pt')
    
    # ç³å­”å®šä½å‚æ•°
    # é˜ˆå€¼ï¼šè¶Šå°è¶Šé»‘ã€‚ç³å­”æ˜¯çœ¼ç›é‡Œæœ€é»‘çš„åœ°æ–¹ã€‚
    # å¦‚æœç¯å¢ƒå¾ˆäº®ï¼ŒæŠŠè¿™ä¸ªå€¼è°ƒä½ (e.g., 30)ï¼›å¦‚æœç¯å¢ƒæš—ï¼Œè°ƒé«˜ (e.g., 60)
    PUPIL_THRESH = 40 
    
    conf_threshold = 0.45
    device = 0 if torch.cuda.is_available() else 'cpu'
    # ==============================================

    # æ£€æŸ¥æ¨¡å‹
    if not os.path.exists(model_path):
        print(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹ï¼š{model_path}\nè¯·ä¿®æ”¹ä»£ç é‡Œçš„ task_nameï¼")
        return
    
    print(f"ğŸ“¥ åŠ è½½æ¨¡å‹: {model_path} ...")
    try:
        model = YOLO(model_path)
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return

    cap = cv2.VideoCapture(0)
    # æé«˜ä¸€ç‚¹åˆ†è¾¨ç‡ï¼Œè®©ç³å­”æ›´æ¸…æ™°
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

    if not cap.isOpened():
        print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        return

    print("âœ… ç³»ç»Ÿå¯åŠ¨ï¼æŒ‰ 'q' é€€å‡ºï¼ŒæŒ‰ 'w'/'s' è°ƒæ•´é˜ˆå€¼ã€‚")
    print(f"å½“å‰äºŒå€¼åŒ–é˜ˆå€¼: {PUPIL_THRESH}")

    prev_time = 0

    while True:
        ret, frame = cap.read()
        if not ret: break

        # 1. YOLO æ¨ç†
        results = model.predict(source=frame, conf=conf_threshold, device=device, verbose=False)
        
        # 2. æ‹¿åˆ°é¢„æµ‹æ¡†
        boxes = results[0].boxes
        
        # åœ¨åŸå›¾ä¸Šç”» YOLO çš„æ¡† (ä¹Ÿå¯ä»¥è‡ªå·±ç”»ï¼Œè¿™é‡Œç”¨ ultralytics è‡ªå¸¦çš„æ–¹ä¾¿ç‚¹)
        # ä½†ä¸ºäº†ç”»çº¢ç‚¹ï¼Œæˆ‘ä»¬å°½é‡åœ¨ copy ä¸Šç”»ï¼Œæˆ–è€…æœ€åå†ç”»æ¡†
        annotated_frame = frame.copy()

        for box in boxes:
            # è·å–åæ ‡ (x1, y1, x2, y2)
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            
            # ç»˜åˆ¶ YOLO æ¡† (ç»¿è‰²)
            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(annotated_frame, "Eye", (x1, y1 - 10), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

            # ================= ğŸ‘ï¸ OpenCV ç³å­”å®šä½æ ¸å¿ƒç®—æ³• =================
            
            # A. è£å‰ªå‡ºçœ¼ç›åŒºåŸŸ (ROI)
            # æ³¨æ„è¾¹ç•Œæ£€æŸ¥ï¼Œé˜²æ­¢æŠ¥é”™
            eye_roi = frame[max(0, y1):min(frame.shape[0], y2), max(0, x1):min(frame.shape[1], x2)]
            
            if eye_roi.size > 0:
                # B. è½¬ç°åº¦
                gray_roi = cv2.cvtColor(eye_roi, cv2.COLOR_BGR2GRAY)
                
                # C. é«˜æ–¯æ¨¡ç³Š (å»å™ª)
                blurred_roi = cv2.GaussianBlur(gray_roi, (7, 7), 0)
                
                # D. äºŒå€¼åŒ– (Inverse: é»‘çš„å˜ç™½ï¼Œç™½çš„å˜é»‘ï¼Œæ–¹ä¾¿æ‰¾è½®å»“)
                _, binary_roi = cv2.threshold(blurred_roi, PUPIL_THRESH, 255, cv2.THRESH_BINARY_INV)
                
                # E. æŸ¥æ‰¾è½®å»“
                contours, _ = cv2.findContours(binary_roi, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
                
                # F. æ‰¾æœ€å¤§çš„è½®å»“ (å‡è®¾æœ€å¤§çš„é»‘è‰²å—æ˜¯ç³å­”)
                contours = sorted(contours, key=lambda x: cv2.contourArea(x), reverse=True)
                
                if len(contours) > 0:
                    pupil_contour = contours[0]
                    
                    # è®¡ç®—é‡å¿ƒ (Moments)
                    M = cv2.moments(pupil_contour)
                    if M["m00"] != 0:
                        cx = int(M["m10"] / M["m00"])
                        cy = int(M["m01"] / M["m00"])
                        
                        # G. åæ ‡æ˜ å°„ (ROI åæ ‡ -> å…¨å±€åæ ‡)
                        global_cx = x1 + cx
                        global_cy = y1 + cy
                        
                        # H. ç”»çº¢ç‚¹ (ç³å­”ä¸­å¿ƒ) ğŸ”´
                        cv2.circle(annotated_frame, (global_cx, global_cy), 4, (0, 0, 255), -1)
                        
                        # ç”»åå­—å‡†æ˜Ÿè¾…åŠ©
                        cv2.line(annotated_frame, (global_cx - 5, global_cy), (global_cx + 5, global_cy), (0, 0, 255), 1)
                        cv2.line(annotated_frame, (global_cx, global_cy - 5), (global_cx, global_cy + 5), (0, 0, 255), 1)

            # =============================================================

        # è®¡ç®— FPS
        curr_time = time.time()
        fps = 1 / (curr_time - prev_time)
        prev_time = curr_time
        
        # æ˜¾ç¤ºä¿¡æ¯
        cv2.putText(annotated_frame, f"FPS: {int(fps)}", (10, 30), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.putText(annotated_frame, f"Threshold: {PUPIL_THRESH} (Press W/S to adjust)", (10, 60), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)

        cv2.imshow('YOLOv8 + OpenCV Pupil Tracking', annotated_frame)

        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            break
        elif key == ord('w'): # å¢åŠ é˜ˆå€¼
            PUPIL_THRESH = min(255, PUPIL_THRESH + 5)
        elif key == ord('s'): # å‡å°‘é˜ˆå€¼
            PUPIL_THRESH = max(1, PUPIL_THRESH - 5)

    cap.release()
    cv2.destroyAllWindows()

if __name__ == '__main__':
    run_pupil_tracking()